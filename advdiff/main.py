# -*- coding: utf-8 -*-
"""
Created on Thu May  7 22:13:40 2020

@author: Guttorm & Ketil

"""
# TODO: Check enviroment variable --inline for performance increase. Cannot be done for python 3.8
# TODO: Check what FiPY solver is used. Maybe current solver is inefficient. Scipy solver is used however no other solver can be used with this version of python.

#%% Read libraries
import sys
import configparser
import logging
import numpy                  as np
import time                   as TIME
import multiprocessing        as mp
import Code.tracer_transport  as tt
from Tools.local_variable_treatment import global_to_local_variables
from Tools.directory_tools    import data_cleanup
from Tools.file_loader        import load_probes, load_sources, load_velocity
from Tools.data_processing    import get_global_attributes, get_probe_attributes, get_source_attributes, get_velocity_attributes
from Tools.data_processing    import get_sweeps, get_source_location_and_probability, get_mean_dt
from Tools.post_processing    import store_fields_to_netcdf, store_mass_to_netcdf, store_probes_to_netcdf, store_stats_to_netcdf, post_process_output
from Tools.parser_tools       import strtolist, strtoBool
from Tools.mesh_generator     import initialize_meshes
from datetime                 import datetime
from tqdm.auto                import tqdm


#%% Define the fipy framework
def run_source(tag, config, local_variable_generator, attrs, use_cpus=-1):
    """
    Runs a simulation using FiPy around a single source. The local variables are generated by the local_variable_generator. The results are saved as
    netcdf files in Outdata/

    Parameters
    ----------
    tag                      : int
                               Source tag denoting which source is being run.
    config                   : setup.ini
                               Config file with relevant variables and setup configurations.
    local_variable_generator : object
                               A global_to_local_velocity object that can generate local variables for use in each simulation.
    attrs                    : dict
                               Dictionary containing attributes for output. 
    use_cpus                 : int
                               Integer denoting how many cpus are being used in parallel. This is only used for the positioning the progressbars properly. 
                               If set to < 1 then progressbars will load sequentally, which works ok but might be a bit buggy. Default -1.
    
    Returns
    -------
    avg_process_time : float 
                       Average process time per timestep dt in seconds.
    """
    ### START INDEPENDENT LOGGER INSIDE THREAD ###
    levels = {'DEBUG': logging.DEBUG, 'INFO': logging.INFO, 'WARNING': logging.WARNING, 'CRITICAL': logging.CRITICAL}
    logging.basicConfig(format   = '[%(levelname)s] %(message)s', 
                        level    = levels[config['DEFAULT']['verbose'].upper()], 
                        handlers = [logging.FileHandler(config['paths']['outdata_path']+'debug.log'), logging.StreamHandler(sys.stdout)])

    ### PROGRESSION BAR ###
    enable_pbar   = strtoBool(config['DEFAULT']['progress_bar'])          # Enable progressbar?
    position_pbar = int(tag % use_cpus) if not use_cpus < 1 else int(tag) # Position of progressbar
    desc_pbar     = f'Source: {str(tag)}'                                 # Progression bar prefix
    
    ### GET LOCAL VARIABLES ###
    velocity = local_variable_generator.get_local_velocity(tag=tag, extrap_from_A=False) # Get local velocity. Extrapolation is based on computational grid.
    if velocity is None:                                                                 # If the velocity is None, then we want to ignore the source.
        return np.nan                                                                    # And, if we want to ignore the source, we quit the simulation now...
    source   = local_variable_generator.get_local_source(tag=tag)                        # Get source location
    probes   = local_variable_generator.get_probe_locations(tag=tag)                     # Get probe locations
    meshdict = local_variable_generator.get_local_meshes(tag=tag)                        # Get local meshes

    try:
        ### START ADVDIFF ###
        logging.info('Starting source: {}'.format(str(tag))) if not enable_pbar else None # Do not print status if progression bar is enabled
        
        # What variables to store
        store_stats  = strtoBool(config['output']['store_stats'])                                 
        store_fields = strtoBool(config['output']['store_fields']) 
        store_uv     = strtoBool(config['output']['store_uv'])     
        store_mass   = strtoBool(config['output']['store_mass'])       
        store_probes = strtoBool(config['output']['store_probes']) if probes is not None else False 

        # Get timestep sizes and number of sweeps based on maximum allowed stepsize
        mean_dt = get_mean_dt(dataset=velocity)  # Mean dt length of dataset
        sweeps  = get_sweeps(config, mean_dt)    # Get number of sweeps per dt
        
        ### INITIALIZE FiPy SOLVER ###
        advdiff = tt.tracer_transport(
                conv_type         = str(config['setup']['convection_type']),
                diff_type         = str(config['setup']['diffusion_type']),
                BC_type           = str(config['setup']['BC_type']),
                D                 = float(config['setup']['D']),
                step_N_stats      = strtolist(config['setup']['step_N_stats'], dtype=int),
                step_N_fields     = int(config['setup']['step_N_fields']),
                extrap_nans       = strtoBool(config['grid']['extrap_nans']),       # Keep this True
                return_structured = strtoBool(config['setup']['return_structured']),
                source            = source,
                probes            = probes,
                meshdict          = meshdict,
                )
        
        advdiff.set_stat_variables(variables=strtolist(config['output']['stat_variables'], dtype=str)) # Set what statistics to keep.
        
        ### RUN SIMULATION ###
        outdata = advdiff.run(
                velocity      = velocity,  
                sweeps        = sweeps, 
                store_stats   = store_stats,            
                store_fields  = store_fields,   
                store_uv      = store_uv,
                store_probes  = store_probes,   
                store_mass    = store_mass, 
                enable_pbar   = enable_pbar,
                desc_pbar     = desc_pbar,
                position_pbar = position_pbar, 
                )

        # Add local attributes to global attributes
        location, location_probability = get_source_location_and_probability(source=source)
        attrs['source tag']            = tag
        attrs['Origin']                = location
        attrs['location_probability']  = location_probability

        ### STATISTICS ###
        if store_stats:                            
            stats = outdata['stats']                                     # Get statistics
            store_stats_to_netcdf(config, stats, tag, meshdict, attrs)   # Store statistics
            
        ### FIELDS ###
        if store_fields:
            fields = outdata['fields']                                   # Concatenate fields over all times
            store_fields_to_netcdf(config, fields, tag, meshdict, attrs) # Store fields
        
        ### PROBES ###
        if store_probes:
            probes = outdata['probes']                         # Concatenate probes over all times
            store_probes_to_netcdf(config, probes, tag, attrs) # Store probes

        ### MASS ###
        if store_mass:
            mass = outdata['mass']                             # Concatenate masses over all times
            store_mass_to_netcdf(config, mass, tag, attrs)     # Store mass

        logging.info('Source {} done...'.format(str(tag))) if not enable_pbar else None

        return outdata['process_time'] # Return average process time for each time-step
    
    except Exception as e:
        logging.critical('The simulation for source {} ran into an unforeseen problem and could not terminate.'.format(str(tag)))
        logging.critical('The exception was: {}\n'.format(e))
        return np.nan

#%%
def main(config, sources=None, global_velocity=None, probes=None):
    """
    Main function to run the AdvDiff module.

    It gets all user parameters by loading the config file at 'Indata/setup.ini'.

    Parameters
    ----------
    config          : config.ini
                      Config file containing all user inputs.  
    sources         : xarray dataset, optional
                      An xarray dataset containing source locations, by default None. If None, load by using config.
    global_velocity : xarray dataset, optional
                      An xarray dataset containing the global velocities in unstructured form, by default None. If None, load by using config.
    probes          : xarray dataset, optional
                      An xarray dataset containing probe locations, by default None. If None, load by using config.
    """

    ### COMPUTATION TIME LOGGER ###
    def log_result(result):
        result_list.append(result)

    ### LOADING FILES ###
    logging.info('---- ### LOADING FILES ### ----\n')
    if probes is None:
        probes, *_          = load_probes(config=config)
    if sources is None:
        sources, *_         = load_sources(config=config)
    if global_velocity is None:
        global_velocity, *_ = load_velocity(config=config)

    ### GET ATTRIBUTES ###
    probes_attrs   = get_probe_attributes(probes)
    velocity_attrs = get_velocity_attributes(global_velocity)
    sources_attrs  = get_source_attributes(sources)
    num_sources    = sources.dims['source']
    
    ### SET UP NUMBER OF CPUs TO UTILIZE ###
    avail_cpus = mp.cpu_count()
    max_cpus   = int(config['DEFAULT']['max_cpus'])
    if max_cpus < 1: 
        max_cpus = avail_cpus 
    use_cpus = min(max_cpus, avail_cpus, num_sources)
    
    ### PRINT INFORMATION ###
    logging.info('---- ### SETUP INFO ### ----\n')
    logging.info('SOURCES:')
    logging.info('Getting sources from:        {}'.format(sources_attrs['Source file']))
    logging.info('Number for source locations: {}\n'.format(str(num_sources)))
    
    logging.info('PROBES: ')
    logging.info('Reading probes from:         {}'.format(probes_attrs['Probe file']))
    logging.info('Number for probe locations:  {}\n'.format(str(probes_attrs['Num probes'])))
    
    logging.info('VELOCITY: ')
    logging.info('Reading velocity from:       {}'.format(velocity_attrs['Velocity file']))
    logging.info('Depth:                       {}'.format(config['velocity']['depth']))
    logging.info('Use velocity timer:          {}'.format(config['setup']['use_custom_timer']))
    logging.info('Fill type:                   {}'.format(config['velocity']['fill_type'])) 
    logging.info('Allow synthetic translation: {}'.format(config['velocity']['allow_synthetic_translation'])) 
    logging.info('Allow synthetic scaling:     {}\n'.format(config['velocity']['allow_synthetic_scaling']))

    logging.info('OUTPUTS: ')
    logging.info('Store outdata in:            {}'.format(config['paths']['outdata_path']))
    logging.info('Store stats:                 {}'.format(config['output']['store_stats']))
    logging.info('Store fields:                {}'.format(config['output']['store_fields']))
    logging.info('Store probes:                {}'.format(config['output']['store_probes']))
    logging.info('Store mass:                  {}'.format(config['output']['store_mass']))
    logging.info('Store uv:                    {}'.format(config['output']['store_uv']))
    logging.info('Generate global statistics:  {}'.format(config['output']['global_stats']))      if strtoBool(config['output']['store_stats'])  else None
    logging.info('Generate global fields:      {}'.format(config['output']['global_fields']))     if strtoBool(config['output']['store_fields']) else None
    logging.info('Generate cumulative probes:  {}'.format(config['output']['cumulate_probes']))   if strtoBool(config['output']['store_probes']) else None
    logging.info('Field downsampling enabled:  {}'.format(config['output']['downsample']))
    logging.info('Field downsampling factor:   {}\n'.format(config['output']['downsampling_factor']))

    logging.info('SETUP: ')
    logging.info('Start time:                  {}'.format(config['setup']['time_start']))                                      if not strtoBool(config['setup']['use_custom_timer']) else None
    logging.info('Time delta:                  {}{}'.format(config['setup']['time_delta'],config['setup']['time_delta_unit'])) if not strtoBool(config['setup']['use_custom_timer']) else None
    logging.info('Time seed:                   {}'.format(config['setup']['time_seed']))                                       if not strtoBool(config['setup']['use_custom_timer']) and config['setup']['time_start'] == 'Random' else None
    logging.info('Start date:                  {}'.format(velocity_attrs['Start date']))
    logging.info('End date:                    {}'.format(velocity_attrs['End date']))
    logging.info('Mean dt:                     {}s'.format(str(velocity_attrs['mean_dt'])))
    logging.info('Sweeps per dt:               {}\n'.format(config['setup']['sweeps']))

    logging.info('ADVDIFF: ')
    logging.info('Boundary Condition type:     {}'.format(config['setup']['BC_type']))
    logging.info('Convection type:             {}'.format(config['setup']['convection_type']))
    logging.info('Diffusion type:              {}'.format(config['setup']['diffusion_type']))
    logging.info('Diffusion constant (D):      {}'.format(config['setup']['D']))
    logging.info('Computational mesh type:     {}-mesh'.format(config['grid']['type']))
    logging.info('Output mesh type:            {}-mesh'.format(config['grid']['type_out']))
    logging.info('Local grid width  (Lx):      {}'.format(config['grid']['Lx']))
    logging.info('Local grid height (Ly):      {}'.format(config['grid']['Ly']))
    logging.info('nx comp mesh:                {}'.format(config['grid']['nx']))               if config['grid']['type'] != 'tri' else None
    logging.info('ny comp mesh:                {}'.format(config['grid']['ny']))               if config['grid']['type'] != 'tri' else None
    logging.info('Maxvol comp mesh:            {}'.format(config['grid']['maxvol']))           if config['grid']['type'] == 'tri' else None
    logging.info('Minvol comp mesh:            {}'.format(config['grid']['minvol']))           if config['grid']['type'] == 'tri' else None
    logging.info('Reduction factor:            {}'.format(config['grid']['reduction_factor'])) if config['grid']['type'] == 'exp' else None
    logging.info('nx out mesh:                 {}'.format(config['grid']['nx']))     
    logging.info('ny out mesh:                 {}'.format(config['grid']['ny']))     
    logging.info('Extrapolate NANs:            {}'.format(config['grid']['extrap_nans']))
    logging.info('Delta stats skips:           {}'.format(config['setup']['step_N_stats']))
    logging.info('Delta field skips:           {}\n'.format(config['setup']['step_N_fields']))
    
    logging.info('CPUs :')
    logging.info('Available CPUs: {}'.format(str(avail_cpus)))
    logging.info('Scheduled CPUs: {}'.format(config['DEFAULT']['max_cpus']))
    logging.info('start_pool:     {}\n'.format(str(use_cpus)))


    ### SET UP GLOBAL ATTRIBUTES ###
    # Get attributes that are in common for all sources
    attrs = get_global_attributes(config         = config, 
                                  sources_attrs  = sources_attrs, 
                                  velocity_attrs = velocity_attrs,
                                  probes_attrs   = probes_attrs, 
                                  )   


    ### MESH GENERATION ### 
    # Generate meshes centered at (0,0) which can be translated to each source
    logging.info('---- ### GENERATING MESHES ### ----')
    meshdict = initialize_meshes(grid_type        = str(config['grid']['type']), 
                                 grid_type_out    = str(config['grid']['type_out']),
                                 Lx               = float(config['grid']['Lx']),
                                 Ly               = float(config['grid']['Ly']),
                                 nx               = int(config['grid']['nx']),
                                 ny               = int(config['grid']['ny']),
                                 minvol           = float(config['grid']['minvol']),
                                 maxvol           = float(config['grid']['maxvol']),
                                 reduction_factor = float(config['grid']['reduction_factor']),
                                 power            = float(config['grid']['power'])) 


    ### GLOBAL TO LOCAL VELOCITY GENERATOR ###
    # Local variable generator gives the needed local variables used around each source
    logging.info('---- ### INITIALIZING LOCAL VARIABLE GENERATOR ### ----')
    local_variable_generator = global_to_local_variables(config          = config, 
                                                         global_velocity = global_velocity, 
                                                         sources         = sources, 
                                                         probes          = probes, 
                                                         meshdict        = meshdict)
    

    ### RUN ADVDIFF SIMULATIONS ###
    logging.info('---- ### RUNNING SIMULATION ### ----') 
    
    start_time = TIME.time()
    result_list = []
    tqdm.set_lock(mp.RLock())
    pool = mp.Pool(processes=use_cpus, initializer=tqdm.set_lock, initargs=(tqdm.get_lock(),))
    for ii in range(num_sources):
        pool.apply_async(run_source, 
                         args=(ii, config, local_variable_generator, attrs, use_cpus), 
                         callback=log_result)
    pool.close()
    pool.join()
    end_time = TIME.time()
    
    print()
    logging.info('All simulations done. The total simulation time was: {0:.2f}s'.format(end_time - start_time))  
    logging.info('The average process time was:                        {0:.4f}s'.format(np.nanmean(result_list)))               
    logging.info('---- ### SIMULATION ENDED ### ----\n')
    
    ### POST-PROCESSING OF OUTDATA ###
    logging.info('---- ### POST-PROCESSING OUTDATA ### ----\n') 
    post_process_output(config, weight_source=strtoBool(config['output']['weight_source']), sum_source=False)
    

    ### CREATE COPY OF CURRENT CONFIG FILE IN OUTPUT FOR REPRODUCIBILITY ###
    with open(config['paths']['outdata_path']+'AdvDiff.ini', 'w') as configfile:
        config.write(configfile)
    

    ### VISUALIZE ###
    if strtoBool(config['visualizer']['plot']):
        logging.info('---- ### VISUALIZING RESULTS ### ----\n')
        from visualize import visualizer
        visualizer(config=config)


if __name__ == '__main__':

    ### READ CONFIG FILE ###
    config=configparser.ConfigParser(allow_no_value=True)
    config.optionxform = str  # preserve case for letters
    config.read('/external/settings/AdvDiff.ini')
    
    ### DATA CLEANUP OF PREVIOUS RUNS ###
    data_cleanup(config=config) # Make sure this comes before anything is stored

    ### SET UP LOGGER ###
    levels = {'DEBUG': logging.DEBUG, 'INFO': logging.INFO, 'WARNING': logging.WARNING, 'CRITICAL': logging.CRITICAL}
    logging.basicConfig(format   = '[%(levelname)s] %(message)s', 
                        level    = levels[config['DEFAULT']['verbose'].upper()], 
                        handlers = [logging.FileHandler(config['paths']['outdata_path']+'debug.log'), logging.StreamHandler(sys.stdout)])
    logging.info(f'AdvDiff Log: {datetime.now().strftime("%d.%m.%Y-%H.%M.%S")}\n')

    ### RUN ADVDIFF MODULE ###
    main(config)

    ### CLOSE LOGGER ###
    logging.shutdown()
